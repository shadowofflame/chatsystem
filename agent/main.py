"""
FastAPI Agent Server
æä¾› HTTP API æ¥å£ä¾› Java åç«¯è°ƒç”¨
æ”¯æŒ --stdio æ¨¡å¼å¯ç”¨ LangGraph STDIO
"""

import os
import sys
import argparse
from typing import Optional, List
from contextlib import asynccontextmanager

from fastapi import FastAPI, HTTPException, UploadFile, File, Form
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel, Field
import uvicorn

from chatbot import ChatbotWithMemory
from langgraph_agent import LangGraphAgent
from tools import FileHandler


# é…ç½®: é€‰æ‹©ä½¿ç”¨å“ªä¸ª agent (é»˜è®¤ä½¿ç”¨LangGraph)
USE_LANGGRAPH = os.getenv("USE_LANGGRAPH", "true").lower() == "true"

# å…¨å±€ agent å®ä¾‹
chatbot: Optional[ChatbotWithMemory] = None
langgraph_agent: Optional[LangGraphAgent] = None
file_handler: Optional[FileHandler] = None


@asynccontextmanager
async def lifespan(app: FastAPI):
    """åº”ç”¨ç”Ÿå‘½å‘¨æœŸç®¡ç†"""
    global chatbot, langgraph_agent, file_handler
    
    # åˆå§‹åŒ–æ–‡ä»¶å¤„ç†å™¨
    file_handler = FileHandler(workspace_dir="./workspace")
    print("âœ… æ–‡ä»¶å¤„ç†å™¨åˆå§‹åŒ–å®Œæˆ")
    
    if USE_LANGGRAPH:
        print("æ­£åœ¨åˆå§‹åŒ– LangGraph Agent...")
        try:
            langgraph_agent = LangGraphAgent(
                memory_dir="./chat_memory_db",
                workspace_dir="./workspace"
            )
            print("âœ… LangGraph Agent åˆå§‹åŒ–å®Œæˆ")
        except Exception as e:
            print(f"âŒ åˆå§‹åŒ–å¤±è´¥: {e}")
            raise
    else:
        print("æ­£åœ¨åˆå§‹åŒ– Chatbot Agent...")
        try:
            chatbot = ChatbotWithMemory(
                memory_dir="./chat_memory_db",
                short_term_limit=10,
                retrieve_memories=5
            )
            print("âœ… Chatbot Agent åˆå§‹åŒ–å®Œæˆ")
        except Exception as e:
            print(f"âŒ åˆå§‹åŒ–å¤±è´¥: {e}")
            raise
    
    yield
    
    print("æ­£åœ¨å…³é—­ Agent...")


# åˆ›å»º FastAPI åº”ç”¨
app = FastAPI(
    title="Chatbot Agent API",
    description="å¸¦æœ‰é•¿æ—¶è®°å¿†çš„å¯¹è¯æœºå™¨äºº Agent æœåŠ¡ (æ”¯æŒ LangGraph)",
    version="2.0.0",
    lifespan=lifespan
)

# é…ç½® CORS
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)


# è¯·æ±‚/å“åº”æ¨¡å‹
class ChatRequest(BaseModel):
    message: str = Field(..., description="ç”¨æˆ·æ¶ˆæ¯")
    session_id: str = Field(default="default", description="ä¼šè¯ID")
    enable_web_search: bool = Field(default=False, description="æ˜¯å¦å¯ç”¨è”ç½‘æœç´¢")
    deep_think: bool = Field(default=False, description="æ˜¯å¦å¯ç”¨æ·±åº¦æ€è€ƒ(TOT)")
    thought_branches: int = Field(default=3, description="æ€è€ƒåˆ†æ”¯æ•°é‡")
    thought_depth: int = Field(default=2, description="æ€è€ƒæ·±åº¦")


class ChatResponse(BaseModel):
    response: str = Field(..., description="åŠ©æ‰‹å›å¤")
    session_id: str = Field(..., description="ä¼šè¯ID")


class MemoryStatsResponse(BaseModel):
    long_term_memories: int = Field(..., description="é•¿æ—¶è®°å¿†æ•°é‡")
    short_term_messages: int = Field(..., description="çŸ­æ—¶è®°å¿†æ¶ˆæ¯æ•°é‡")


class SummarizeRequest(BaseModel):
    text: str = Field(..., description="éœ€è¦æ€»ç»“çš„æ–‡æœ¬")
    max_length: Optional[int] = Field(15, description="æ€»ç»“çš„æœ€å¤§é•¿åº¦ï¼ˆå­—æ•°ï¼‰")


class SummarizeResponse(BaseModel):
    summary: str = Field(..., description="æ€»ç»“ç»“æœ")


class ExtractRequest(BaseModel):
    text: str = Field(..., description="éœ€è¦æå–ä¿¡æ¯çš„æ–‡æœ¬")


class ExtractResponse(BaseModel):
    extracted_info: str = Field(..., description="æå–çš„å…³é”®ä¿¡æ¯")


class TranslateRequest(BaseModel):
    text: str = Field(..., description="éœ€è¦ç¿»è¯‘çš„æ–‡æœ¬")
    target_language: str = Field(default="English", description="ç›®æ ‡è¯­è¨€")


class TranslateResponse(BaseModel):
    translated_text: str = Field(..., description="ç¿»è¯‘åçš„æ–‡æœ¬")


class SuccessResponse(BaseModel):
    success: bool = Field(..., description="æ“ä½œæ˜¯å¦æˆåŠŸ")
    message: str = Field(default="", description="æ¶ˆæ¯")


# API è·¯ç”±
@app.get("/health")
async def health_check():
    """å¥åº·æ£€æŸ¥"""
    return {"status": "healthy", "service": "chatbot-agent"}


@app.post("/api/chat", response_model=ChatResponse)
async def chat(request: ChatRequest):
    """
    å¯¹è¯æ¥å£
    
    æ¥æ”¶ç”¨æˆ·æ¶ˆæ¯ï¼Œè¿”å›åŠ©æ‰‹å›å¤
    æ”¯æŒ enable_web_search å‚æ•°å¼ºåˆ¶å¯ç”¨è”ç½‘æœç´¢
    """
    global chatbot, langgraph_agent
    
    if USE_LANGGRAPH:
        if langgraph_agent is None:
            raise HTTPException(status_code=503, detail="LangGraph Agent not initialized")
        
        try:
            # å¦‚æœå¯ç”¨è”ç½‘æœç´¢ï¼Œä½¿ç”¨å¸¦æœç´¢çš„æ–¹æ³•
            if request.enable_web_search:
                response = langgraph_agent.chat_with_search(
                    request.message,
                    deep_think=request.deep_think,
                    max_branches=request.thought_branches,
                    max_depth=request.thought_depth
                )
            else:
                response = langgraph_agent.chat(
                    request.message,
                    deep_think=request.deep_think,
                    max_branches=request.thought_branches,
                    max_depth=request.thought_depth
                )
            return ChatResponse(
                response=response,
                session_id=request.session_id
            )
        except Exception as e:
            raise HTTPException(status_code=500, detail=str(e))
    else:
        if chatbot is None:
            raise HTTPException(status_code=503, detail="Chatbot not initialized")
        
        try:
            response = chatbot.chat(request.message)
            return ChatResponse(
                response=response,
                session_id=request.session_id
            )
        except Exception as e:
            raise HTTPException(status_code=500, detail=str(e))


@app.get("/api/stats", response_model=MemoryStatsResponse)
async def get_stats():
    """
    è·å–è®°å¿†ç»Ÿè®¡ä¿¡æ¯
    """
    global chatbot, langgraph_agent
    
    if USE_LANGGRAPH:
        if langgraph_agent is None:
            raise HTTPException(status_code=503, detail="LangGraph Agent not initialized")
        
        try:
            stats = langgraph_agent.get_memory_stats()
            return MemoryStatsResponse(
                long_term_memories=stats["long_term_memories"],
                short_term_messages=0  # LangGraphç‰ˆæœ¬æ²¡æœ‰çŸ­æœŸè®°å¿†ç»Ÿè®¡
            )
        except Exception as e:
            raise HTTPException(status_code=500, detail=str(e))
    else:
        if chatbot is None:
            raise HTTPException(status_code=503, detail="Chatbot not initialized")
        
        try:
            stats = chatbot.get_memory_stats()
            return MemoryStatsResponse(
                long_term_memories=stats["long_term_memories"],
                short_term_messages=stats["short_term_messages"]
            )
        except Exception as e:
            raise HTTPException(status_code=500, detail=str(e))


@app.post("/api/memory/clear-short-term", response_model=SuccessResponse)
async def clear_short_term_memory():
    """
    æ¸…é™¤çŸ­æ—¶è®°å¿†
    """
    global chatbot
    
    if chatbot is None:
        raise HTTPException(status_code=503, detail="Chatbot not initialized")
    
    try:
        chatbot.clear_short_term_memory()
        return SuccessResponse(success=True, message="Short-term memory cleared")
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


@app.post("/api/memory/clear-all", response_model=SuccessResponse)
async def clear_all_memory():
    """
    æ¸…é™¤æ‰€æœ‰è®°å¿†
    """
    global chatbot, langgraph_agent
    
    if USE_LANGGRAPH:
        if langgraph_agent is None:
            raise HTTPException(status_code=503, detail="LangGraph Agent not initialized")
        try:
            langgraph_agent.clear_all_memory()
            return SuccessResponse(success=True, message="All memory cleared")
        except Exception as e:
            raise HTTPException(status_code=500, detail=str(e))
    else:
        if chatbot is None:
            raise HTTPException(status_code=503, detail="Chatbot not initialized")
        try:
            chatbot.clear_all_memory()
            return SuccessResponse(success=True, message="All memory cleared")
        except Exception as e:
            raise HTTPException(status_code=500, detail=str(e))


@app.post("/api/summarize", response_model=SummarizeResponse)
async def summarize_text(request: SummarizeRequest):
    """
    æ–‡æœ¬æ€»ç»“æ¥å£
    
    å¯¹è¾“å…¥çš„æ–‡æœ¬è¿›è¡Œæ™ºèƒ½æ€»ç»“
    """
    global chatbot, langgraph_agent
    
    if USE_LANGGRAPH:
        if langgraph_agent is None:
            raise HTTPException(status_code=503, detail="LangGraph Agent not initialized")
        try:
            summary = langgraph_agent.summarize(request.text, request.max_length)
            return SummarizeResponse(summary=summary)
        except Exception as e:
            raise HTTPException(status_code=500, detail=str(e))
    else:
        if chatbot is None:
            raise HTTPException(status_code=503, detail="Chatbot not initialized")
        try:
            summary = chatbot.summarize(request.text, request.max_length)
            return SummarizeResponse(summary=summary)
        except Exception as e:
            raise HTTPException(status_code=500, detail=str(e))


@app.post("/api/extract", response_model=ExtractResponse)
async def extract_information(request: ExtractRequest):
    """
    ä¿¡æ¯æå–æ¥å£
    
    ä»æ–‡æœ¬ä¸­æå–å…³é”®ä¿¡æ¯
    """
    global chatbot, langgraph_agent
    
    if USE_LANGGRAPH:
        if langgraph_agent is None:
            raise HTTPException(status_code=503, detail="LangGraph Agent not initialized")
        try:
            extracted = langgraph_agent.extract_information(request.text)
            return ExtractResponse(extracted_info=extracted)
        except Exception as e:
            raise HTTPException(status_code=500, detail=str(e))
    else:
        if chatbot is None:
            raise HTTPException(status_code=503, detail="Chatbot not initialized")
        try:
            extracted = chatbot.extract_information(request.text)
            return ExtractResponse(extracted_info=extracted)
        except Exception as e:
            raise HTTPException(status_code=500, detail=str(e))


@app.post("/api/translate", response_model=TranslateResponse)
async def translate_text(request: TranslateRequest):
    """
    ç¿»è¯‘æ¥å£
    
    å°†æ–‡æœ¬ç¿»è¯‘æˆæŒ‡å®šè¯­è¨€
    """
    global chatbot, langgraph_agent
    
    if USE_LANGGRAPH:
        if langgraph_agent is None:
            raise HTTPException(status_code=503, detail="LangGraph Agent not initialized")
        try:
            translated = langgraph_agent.translate(request.text, request.target_language)
            return TranslateResponse(translated_text=translated)
        except Exception as e:
            raise HTTPException(status_code=500, detail=str(e))
    else:
        if chatbot is None:
            raise HTTPException(status_code=503, detail="Chatbot not initialized")
        try:
            translated = chatbot.translate(request.text, request.target_language)
            return TranslateResponse(translated_text=translated)
        except Exception as e:
            raise HTTPException(status_code=500, detail=str(e))


# æ–‡ä»¶ä¸Šä¼ å“åº”æ¨¡å‹
class FileUploadResponse(BaseModel):
    success: bool
    filename: str = ""
    original_name: str = ""
    filepath: str = ""
    size: int = 0
    error: str = ""


class FileAnalyzeRequest(BaseModel):
    filepath: str = Field(..., description="æ–‡ä»¶è·¯å¾„")
    question: str = Field(default="è¯·åˆ†æè¿™ä¸ªæ–‡ä»¶çš„å†…å®¹", description="å…³äºæ–‡ä»¶çš„é—®é¢˜")


class FileAnalyzeResponse(BaseModel):
    success: bool
    analysis: str = ""
    file_type: str = ""
    error: str = ""


@app.post("/api/upload", response_model=FileUploadResponse)
async def upload_file(file: UploadFile = File(...)):
    """
    æ–‡ä»¶ä¸Šä¼ æ¥å£
    
    ä¸Šä¼ æ–‡ä»¶åˆ°æœåŠ¡å™¨å·¥ä½œç©ºé—´
    """
    global file_handler
    
    if file_handler is None:
        raise HTTPException(status_code=503, detail="File handler not initialized")
    
    try:
        # è¯»å–æ–‡ä»¶å†…å®¹
        content = await file.read()
        
        # ä¿å­˜æ–‡ä»¶
        result = file_handler.save_uploaded_file(file.filename, content)
        
        if result["success"]:
            return FileUploadResponse(
                success=True,
                filename=result["filename"],
                original_name=result["original_name"],
                filepath=result["filepath"],
                size=result["size"]
            )
        else:
            return FileUploadResponse(
                success=False,
                error=result.get("error", "ä¸Šä¼ å¤±è´¥")
            )
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


@app.post("/api/analyze-file", response_model=FileAnalyzeResponse)
async def analyze_file(request: FileAnalyzeRequest):
    """
    åˆ†æä¸Šä¼ çš„æ–‡ä»¶
    
    è¯»å–æ–‡ä»¶å†…å®¹å¹¶ä½¿ç”¨AIè¿›è¡Œåˆ†æ
    """
    global file_handler, langgraph_agent, chatbot
    
    if file_handler is None:
        raise HTTPException(status_code=503, detail="File handler not initialized")
    
    try:
        # è¯»å–æ–‡ä»¶å†…å®¹
        file_result = file_handler.read_uploaded_file_content(request.filepath)
        
        if not file_result["success"]:
            return FileAnalyzeResponse(
                success=False,
                error=file_result.get("error", "è¯»å–æ–‡ä»¶å¤±è´¥")
            )
        
        file_content = file_result["content"]
        file_type = file_result.get("file_type", "unknown")
        
        # æ„å»ºåˆ†ææç¤º
        analysis_prompt = f"""ç”¨æˆ·ä¸Šä¼ äº†ä¸€ä¸ªæ–‡ä»¶ï¼Œè¯·æ ¹æ®æ–‡ä»¶å†…å®¹å›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚

æ–‡ä»¶ç±»å‹: {file_type}
æ–‡ä»¶å†…å®¹:
{file_content[:5000]}{"...(å†…å®¹å·²æˆªæ–­)" if len(file_content) > 5000 else ""}

ç”¨æˆ·é—®é¢˜: {request.question}

è¯·æä¾›è¯¦ç»†çš„åˆ†æå’Œå›ç­”ã€‚"""
        
        # ä½¿ç”¨AIåˆ†æ
        if USE_LANGGRAPH and langgraph_agent:
            analysis = langgraph_agent.chat(analysis_prompt)
        elif chatbot:
            analysis = chatbot.chat(analysis_prompt)
        else:
            raise HTTPException(status_code=503, detail="No agent available")
        
        return FileAnalyzeResponse(
            success=True,
            analysis=analysis,
            file_type=file_type
        )
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


@app.get("/api/files")
async def list_uploaded_files():
    """
    åˆ—å‡ºå·²ä¸Šä¼ çš„æ–‡ä»¶
    """
    global file_handler
    
    if file_handler is None:
        raise HTTPException(status_code=503, detail="File handler not initialized")
    
    try:
        result = file_handler.list_files("uploads")
        return result
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


def run_stdio_mode(args):
    """è¿è¡Œ LangGraph STDIO æ¨¡å¼ï¼ˆçº¯å‘½ä»¤è¡Œï¼Œä¸å¯åŠ¨HTTPæœåŠ¡ï¼‰"""
    print("ğŸš€ å¯åŠ¨ LangGraph STDIO æ¨¡å¼...")
    
    agent = LangGraphAgent(
        model=args.model,
        memory_dir=args.memory,
        workspace_dir=args.workspace,
        default_branches=args.branches,
        default_depth=args.depth,
    )
    
    sys.stdout.write("LangGraph STDIO ready. Type your message and press Enter.\n")
    sys.stdout.flush()
    
    for line in sys.stdin:
        message = line.strip()
        if not message:
            continue
        if message.lower() in ('exit', 'quit', 'q'):
            print("Goodbye!")
            break
        try:
            reply = agent.chat(
                message,
                deep_think=args.deep,
                max_branches=args.branches,
                max_depth=args.depth,
            )
        except Exception as exc:
            reply = f"error: {exc}"
        sys.stdout.write(reply + "\n")
        sys.stdout.flush()


def run_hybrid_mode(args):
    """
    æ··åˆæ¨¡å¼ï¼šåŒæ—¶è¿è¡Œ HTTP API æœåŠ¡å’Œ STDIO äº¤äº’
    - HTTP API åœ¨åå°çº¿ç¨‹è¿è¡Œï¼Œä¾› Java åç«¯è°ƒç”¨
    - STDIO åœ¨ä¸»çº¿ç¨‹è¿è¡Œï¼Œå¯ä»¥ç›´æ¥å‘½ä»¤è¡Œäº¤äº’
    """
    import threading
    import time
    
    print("ğŸš€ å¯åŠ¨æ··åˆæ¨¡å¼ (HTTP API + STDIO)...")
    print(f"   HTTP API: http://localhost:{args.port}")
    print(f"   æ·±åº¦æ€è€ƒ: {'å¼€å¯' if args.deep else 'å…³é—­'}")
    
    # åœ¨åå°çº¿ç¨‹å¯åŠ¨ HTTP æœåŠ¡
    def start_api():
        uvicorn.run(
            "main:app",
            host="0.0.0.0",
            port=args.port,
            reload=False,  # æ··åˆæ¨¡å¼ä¸‹ä¸èƒ½ç”¨ reload
            log_level="warning"  # å‡å°‘æ—¥å¿—å¹²æ‰°
        )
    
    api_thread = threading.Thread(target=start_api, daemon=True)
    api_thread.start()
    
    # ç­‰å¾… API å¯åŠ¨
    time.sleep(3)
    print(f"\nâœ… HTTP API å·²åœ¨åå°è¿è¡Œ (ç«¯å£ {args.port})")
    print("ğŸ’¬ STDIO äº¤äº’å·²å°±ç»ªï¼Œè¾“å…¥æ¶ˆæ¯åå›è½¦å‘é€ï¼Œè¾“å…¥ 'quit' é€€å‡º\n")
    
    # ä½¿ç”¨å…¨å±€çš„ langgraph_agentï¼ˆç”± FastAPI lifespan åˆå§‹åŒ–ï¼‰
    # ä½†è¿™é‡Œéœ€è¦å•ç‹¬åˆ›å»ºä¸€ä¸ªï¼Œå› ä¸º lifespan åœ¨å¦ä¸€ä¸ªçº¿ç¨‹
    agent = LangGraphAgent(
        model=args.model,
        memory_dir=args.memory,
        workspace_dir=args.workspace,
        default_branches=args.branches,
        default_depth=args.depth,
    )
    
    # STDIO äº¤äº’å¾ªç¯
    try:
        while True:
            try:
                message = input("You: ").strip()
            except EOFError:
                break
            
            if not message:
                continue
            if message.lower() in ('exit', 'quit', 'q'):
                print("Goodbye!")
                break
            
            try:
                reply = agent.chat(
                    message,
                    deep_think=args.deep,
                    max_branches=args.branches,
                    max_depth=args.depth,
                )
                print(f"Agent: {reply}\n")
            except Exception as exc:
                print(f"Error: {exc}\n")
    except KeyboardInterrupt:
        print("\nGoodbye!")


def run_api_mode(port: int):
    """è¿è¡Œ FastAPI HTTP æ¨¡å¼"""
    print(f"ğŸš€ å¯åŠ¨ FastAPI HTTP æ¨¡å¼ï¼Œç«¯å£: {port}")
    uvicorn.run(
        "main:app",
        host="0.0.0.0",
        port=port,
        reload=True
    )


if __name__ == "__main__":
    parser = argparse.ArgumentParser(
        description="Chatbot Agent - æ”¯æŒ HTTP APIã€STDIO å’Œæ··åˆæ¨¡å¼"
    )
    parser.add_argument(
        "--stdio", 
        action="store_true", 
        help="çº¯ STDIO æ¨¡å¼ï¼ˆä¸å¯åŠ¨ HTTP æœåŠ¡ï¼‰"
    )
    parser.add_argument(
        "--hybrid", 
        action="store_true", 
        help="æ··åˆæ¨¡å¼ï¼šåŒæ—¶è¿è¡Œ HTTP API å’Œ STDIO äº¤äº’"
    )
    parser.add_argument(
        "--port", 
        type=int, 
        default=int(os.getenv("AGENT_PORT", "8000")), 
        help="HTTP API ç«¯å£ (é»˜è®¤: 8000)"
    )
    parser.add_argument(
        "--deep", 
        action="store_true", 
        help="å¯ç”¨æ·±åº¦æ€è€ƒ (Tree-of-Thought)"
    )
    parser.add_argument(
        "--branches", 
        type=int, 
        default=3, 
        help="æ€è€ƒåˆ†æ”¯æ•°é‡ (é»˜è®¤: 3)"
    )
    parser.add_argument(
        "--depth", 
        type=int, 
        default=2, 
        help="æ€è€ƒæ·±åº¦ (é»˜è®¤: 2)"
    )
    parser.add_argument(
        "--model", 
        default="deepseek-chat", 
        help="æ¨¡å‹åç§° (é»˜è®¤: deepseek-chat)"
    )
    parser.add_argument(
        "--workspace", 
        default="./workspace", 
        help="å·¥ä½œåŒºç›®å½• (é»˜è®¤: ./workspace)"
    )
    parser.add_argument(
        "--memory", 
        default="./chat_memory_db", 
        help="è®°å¿†å­˜å‚¨ç›®å½• (é»˜è®¤: ./chat_memory_db)"
    )
    
    args = parser.parse_args()
    
    if args.stdio:
        run_stdio_mode(args)
    elif args.hybrid:
        run_hybrid_mode(args)
    else:
        run_api_mode(args.port)
